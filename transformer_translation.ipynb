{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIoXskULx4du",
        "outputId": "aae60558-98ed-46f6-fa4f-045ce7c8f571"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting opencc-python-reimplemented\n",
            "  Downloading opencc_python_reimplemented-0.1.7-py2.py3-none-any.whl (481 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m481.8/481.8 kB\u001b[0m \u001b[31m2.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: opencc-python-reimplemented\n",
            "Successfully installed opencc-python-reimplemented-0.1.7\n"
          ]
        }
      ],
      "source": [
        "!pip install opencc-python-reimplemented\n",
        "import time\n",
        "import pathlib\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import tensorflow as tf\n",
        "import jieba\n",
        "from opencc import OpenCC  #pip install opencc-python-reimplemented"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = pathlib.Path('/content/transformer/cmn.txt')\n",
        "path_to_file\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbAkiqNPx5EO",
        "outputId": "2852ae28-597a-405c-8165-289e89e87bc0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "PosixPath('/content/transformer/cmn.txt')"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#数据格式如上图所示\n",
        "#定义一个方法，加载数据文本，并把数据分成输入(中文）数据集，和输出(英文）数据集\n",
        "def load_data(path):\n",
        "    targ = [] #建立输出数据集 列表形式\n",
        "    inp = [] #建立输入数据集 列表形式\n",
        "    text = path.read_text(encoding='utf-8') #读取文件\n",
        "    lines = text.splitlines() #以行为单位读取所有数据\n",
        "    #读取每行数据，用\\t进行分割，只取前两个数据。\n",
        "    pairs = [line.split('\\t')[:2] for line in lines]\n",
        "    for y, x in pairs: #读取pairs的每一数据\n",
        "        targ.append(y) #把第一个数据英文加入到targ\n",
        "        inp.append(x)  #把第二个数据中文加入到inp\n",
        "    return targ, inp"
      ],
      "metadata": {
        "id": "YWFytQ7ByrxE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "targ, inp = load_data(path_to_file)\n",
        "print(len(inp))\n",
        "print(len(targ))\n",
        "print(inp[-10:])\n",
        "print(targ[-10:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 350
        },
        "id": "yixwyNHDyubf",
        "outputId": "60a144f0-ef83-4e68-d7b9-7803bf27d23d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/transformer/cmn.txt'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-4-54c6520f33ee>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtarg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_to_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minp\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-636ad2826b56>\u001b[0m in \u001b[0;36mload_data\u001b[0;34m(path)\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mtarg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#建立输出数据集 列表形式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0minp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#建立输入数据集 列表形式\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0mtext\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'utf-8'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#读取文件\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mlines\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitlines\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#以行为单位读取所有数据\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0;31m#读取每行数据，用\\t进行分割，只取前两个数据。\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pathlib.py\u001b[0m in \u001b[0;36mread_text\u001b[0;34m(self, encoding, errors)\u001b[0m\n\u001b[1;32m   1132\u001b[0m         \"\"\"\n\u001b[1;32m   1133\u001b[0m         \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1134\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'r'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mencoding\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0merrors\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1135\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1136\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/pathlib.py\u001b[0m in \u001b[0;36mopen\u001b[0;34m(self, mode, buffering, encoding, errors, newline)\u001b[0m\n\u001b[1;32m   1117\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1118\u001b[0m             \u001b[0mencoding\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext_encoding\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mencoding\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1119\u001b[0;31m         return self._accessor.open(self, mode, buffering, encoding, errors,\n\u001b[0m\u001b[1;32m   1120\u001b[0m                                    newline)\n\u001b[1;32m   1121\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/transformer/cmn.txt'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#使用OpenCC('t2s') 繁体变简体的方法\n",
        "cc = OpenCC('t2s')"
      ],
      "metadata": {
        "id": "PtZLrR0fyyaa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#定义一个方法，用于把繁体转换成简体，并对句子进行分词。\n",
        "def proce_cn_sentence(cn_text):\n",
        "    text = cc.convert(cn_text) #繁体转换成简体\n",
        "    text = jieba.lcut(text) #读取数据集里的每个数据并进行分词\n",
        "    text = ' '.join(text) #对分好的词用空格链接起来\n",
        "    return text"
      ],
      "metadata": {
        "id": "9MJ_BCOpzKt6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#由于中文是连续的，我们要进行分词，并把每个词语之间加入空格\n",
        "for i in range(len(inp)):\n",
        "    text = proce_cn_sentence(inp[i]) #读取数据集里的每个数据并进行分词\n",
        "    inp[i] = text #用分词好的数据替换数据集中原先的数据"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JUSIQTBezNfQ",
        "outputId": "b5df7185-b3d7-49db-eeab-bd314207b8f6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Building prefix dict from the default dictionary ...\n",
            "DEBUG:jieba:Building prefix dict from the default dictionary ...\n",
            "Dumping model to file cache /tmp/jieba.cache\n",
            "DEBUG:jieba:Dumping model to file cache /tmp/jieba.cache\n",
            "Loading model cost 1.010 seconds.\n",
            "DEBUG:jieba:Loading model cost 1.010 seconds.\n",
            "Prefix dict has been built successfully.\n",
            "DEBUG:jieba:Prefix dict has been built successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "inp[-10:] #我们在来看看inp数据集里的数据\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XsO_6Uj5zSVK",
        "outputId": "85ac39b4-b291-47bb-8fcd-2f1676c892bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['菲律宾 去年 地震 和 海啸 造成 了 超过 6000 人 的 死亡 。',\n",
              " '“ 又 是 汤姆 的 电话 ？ ”   “ 嗯 。 最近 他 每天晚上 都 会 打 过来 。 当时 就 不该 给 他 我 的 号码 的 。 ”',\n",
              " '我 母亲 的 法语 比 我 父亲 的 英语 要 好 ， 所以 他们 通常 用 法语 交流 。',\n",
              " '汤姆 不知 如何 翻译 “ 计算机 ” 一词 ， 因为 同 他 谈话 的 人 从未见过 一台 。',\n",
              " '汤姆 不 喜欢 使用 ” 有色人种 “ 这个 术语 ， 因为 他 认为 ， 根据 这种 说法 白种人 没有 颜色 。',\n",
              " '你 不想 涂 防晒霜 是 你 的 问题 ， 但是 晒伤 了 不要 来 抱怨 。',\n",
              " '即使 是 现在 ， 我 偶尔 还是 想 见到 你 。 不是 今天 的 你 ， 而是 我 记忆 中 曾经 的 你 。',\n",
              " '你 很 容易 把 母语 说 得 通顺 流畅 ， 却 很 容易 把 非 母语 说 得 不 自然 。',\n",
              " '虽然 我 被 公司 解雇 了 ， 但是 我 还 有点 存款 ， 所以 目前 不用 担心 生计 问题 。',\n",
              " '如果 一个 人 在 成人 前 没有 机会 习得 目标语言 ， 他 对 该 语言 的 认识 达到 母语 者 程度 的 机会 是 相当 小 的 。']"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#定义两个常量\n",
        "BUFFZE_SIZE = len(inp)\n",
        "print(BUFFZE_SIZE)\n",
        "BATCH_SIZE = 64"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LzgTvhABzUpD",
        "outputId": "d296d175-2516-42ad-b5d7-a25be3e48af2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "29909\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "#把inp和targ加入到dataset中变成tensor这样有利于tensorflow读取\n",
        "dataset = tf.data.Dataset.from_tensor_slices((inp, targ)).shuffle(BUFFZE_SIZE)\n",
        "dataset = dataset.batch(BATCH_SIZE)"
      ],
      "metadata": {
        "id": "bqx6xS36zcWj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#我们看下dataset中数据的样式\n",
        "for example_input_batch, example_target_batch in dataset.take(1):\n",
        "    print(example_input_batch[:3])\n",
        "    print()\n",
        "    print(example_target_batch[:3])\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gw8oQhWHzcxy",
        "outputId": "3cbcef6c-d074-4e84-ca7f-88ea42d78407"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'\\xe4\\xba\\xba\\xe7\\x94\\x9f \\xe8\\x89\\xaf\\xe8\\x8b\\xa6 \\xe3\\x80\\x82'\n",
            " b'\\xe4\\xbd\\xa0 \\xe6\\x98\\xaf \\xe8\\xae\\xa4\\xe7\\x9c\\x9f \\xe7\\x9a\\x84 \\xe5\\x90\\x97 \\xef\\xbc\\x9f'\n",
            " b'\\xe8\\xbf\\x99\\xe4\\xb8\\xaa \\xe8\\x8b\\xb9\\xe6\\x9e\\x9c \\xe6\\x98\\xaf \\xe5\\x9d\\x8f \\xe7\\x9a\\x84 \\xe3\\x80\\x82'], shape=(3,), dtype=string)\n",
            "\n",
            "tf.Tensor([b'Life is very hard.' b'Are you serious?' b'This apple is bad.'], shape=(3,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#该方法主要是给中文每个句子加上start和end\n",
        "def tf_lower_and_split_punct_cn(text):\n",
        "    #大写变小写\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.strip(text)\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text\n",
        "\n"
      ],
      "metadata": {
        "id": "sjV9CiFnzeoo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_text = tf.constant('去年 在 菲律宾 ， 地震 和 海啸 造成 了 超过 6000 人 的 死亡 。')\n",
        "print(example_text.numpy().decode())\n",
        "print(tf_lower_and_split_punct_cn(example_text).numpy().decode())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QIAJd6gpzibn",
        "outputId": "8276f5f7-02c8-4ac7-cc14-212d050d7e2f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "去年 在 菲律宾 ， 地震 和 海啸 造成 了 超过 6000 人 的 死亡 。\n",
            "[START] 去年 在 菲律宾 ， 地震 和 海啸 造成 了 超过 6000 人 的 死亡 。 [END]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_vocab_size = 15000 #中文词典单词数量的大小\n"
      ],
      "metadata": {
        "id": "igi8edR6zj49"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.keras.layers.TextVectorization 可以批量自动把文本转换成数值id\n",
        "#同时里面的get_vocabulary()方法还可以获得词汇表，\n",
        "#vocabulary_size()方法可以获得词汇表大小\n",
        "input_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct_cn,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "metadata": {
        "id": "imYKFxGCz2R0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#把上面的处理方法应用到输入(中文数据）中\n",
        "input_text_processor.adapt(inp)\n",
        "\n",
        "#获得词汇表\n",
        "input_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nLtdPPPjz36X",
        "outputId": "b8cf649e-329e-49e3-b797-a8aa6d9d99f7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '。', '我', '的', '了', '你', '？']"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_tokens = input_text_processor(example_input_batch)\n",
        "example_tokens"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6iVuCgGqz8RG",
        "outputId": "aa9e4592-8f13-4593-a101-8cde813758c0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(64, 21), dtype=int64, numpy=\n",
              "array([[   2,  778, 7803, ...,    0,    0,    0],\n",
              "       [   2,    8,   13, ...,    0,    0,    0],\n",
              "       [   2,   29,  261, ...,    0,    0,    0],\n",
              "       ...,\n",
              "       [   2,    5,  116, ...,    0,    0,    0],\n",
              "       [   2,   31,  758, ...,    0,    0,    0],\n",
              "       [   2,   11,   32, ...,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#英文处理方法\n",
        "def tf_lower_and_split_punct_en(text):\n",
        "    text = tf.strings.lower(text)\n",
        "    text = tf.strings.regex_replace(text, '[^ a-z.?!,¿]', '')\n",
        "    text = tf.strings.regex_replace(text, '[.?!,¿]', r' \\0 ')\n",
        "    text = tf.strings.strip(text)\n",
        "\n",
        "    text = tf.strings.join(['[START]', text, '[END]'], separator=' ')\n",
        "    return text"
      ],
      "metadata": {
        "id": "1mHxvIEF1uQx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_processor = tf.keras.layers.TextVectorization(\n",
        "    standardize=tf_lower_and_split_punct_en,\n",
        "    max_tokens=max_vocab_size)"
      ],
      "metadata": {
        "id": "5xm3E5a91xbg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "output_text_processor.adapt(targ)\n",
        "output_text_processor.get_vocabulary()[:10]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H-3xXJON1z_9",
        "outputId": "3c6ec4a1-7c51-42d9-9f46-c0949aa08472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['', '[UNK]', '[START]', '[END]', '.', 'the', 'i', 'to', 'you', '?']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def tokenize_pairs(cn, en):\n",
        "    cn = input_text_processor(cn)\n",
        "    en = output_text_processor(en)\n",
        "    return cn, en"
      ],
      "metadata": {
        "id": "HWjprCxy11iU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def make_batches(ds):\n",
        "    return (\n",
        "        ds\n",
        "        .map(tokenize_pairs, num_parallel_calls=tf.data.AUTOTUNE)\n",
        "    )"
      ],
      "metadata": {
        "id": "4AfblIdO1_-G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#应用到dataset数据集上，建立好后期要使用的train_batches数据\n",
        "train_batches = make_batches(dataset)\n",
        "train_batches"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RG9zSkIy2Bo_",
        "outputId": "c8d30e85-bea3-4840-a159-e2ddbb60afbd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_ParallelMapDataset element_spec=(TensorSpec(shape=(None, None), dtype=tf.int64, name=None), TensorSpec(shape=(None, None), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for (batch, (inp, tar)) in enumerate(train_batches.take(3)):\n",
        "    print(batch)\n",
        "    print(inp)\n",
        "    print(tar)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDwbnVvO2DQX",
        "outputId": "7229ec1f-81b6-4989-91eb-a69e7824147f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0\n",
            "tf.Tensor(\n",
            "[[   2  409   11 ...    0    0    0]\n",
            " [   2  162 3644 ...    0    0    0]\n",
            " [   2    5    6 ...    0    0    0]\n",
            " ...\n",
            " [   2   15  135 ...    0    0    0]\n",
            " [   2    5  284 ...    0    0    0]\n",
            " [   2  121    8 ...    0    0    0]], shape=(64, 19), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   2  372  118 ...    0    0    0]\n",
            " [   2  496 6506 ...    0    0    0]\n",
            " [   2   16  409 ...    0    0    0]\n",
            " ...\n",
            " [   2   25   24 ...    0    0    0]\n",
            " [   2    6 3396 ...    0    0    0]\n",
            " [   2   80    8 ...    0    0    0]], shape=(64, 24), dtype=int64)\n",
            "1\n",
            "tf.Tensor(\n",
            "[[   2   11 1865 ...    0    0    0]\n",
            " [   2  333   25 ...    0    0    0]\n",
            " [   2    8   78 ...    0    0    0]\n",
            " ...\n",
            " [   2   17 7129 ...    0    0    0]\n",
            " [   2  717   12 ...    0    0    0]\n",
            " [   2   53   50 ...    0    0    0]], shape=(64, 21), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[  2  12 166 ...   0   0   0]\n",
            " [  2 327  40 ...   0   0   0]\n",
            " [  2  89  68 ...   0   0   0]\n",
            " ...\n",
            " [  2  33  68 ...   0   0   0]\n",
            " [  2  94  11 ...   0   0   0]\n",
            " [  2  40   8 ...   0   0   0]], shape=(64, 20), dtype=int64)\n",
            "2\n",
            "tf.Tensor(\n",
            "[[   2    5  181 ...    0    0    0]\n",
            " [   2  149 2484 ...    0    0    0]\n",
            " [   2    8  419 ...    0    0    0]\n",
            " ...\n",
            " [   2    8   96 ...    0    0    0]\n",
            " [   2   22   49 ...    0    0    0]\n",
            " [   2 2399 2739 ...    0    0    0]], shape=(64, 16), dtype=int64)\n",
            "tf.Tensor(\n",
            "[[   2    6  192 ...    0    0    0]\n",
            " [   2  254 1083 ...    0    0    0]\n",
            " [   2   30   53 ...    0    0    0]\n",
            " ...\n",
            " [   2   45   54 ...    0    0    0]\n",
            " [   2   18   11 ...    0    0    0]\n",
            " [   2    5  134 ...    0    0    0]], shape=(64, 18), dtype=int64)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# PE总体表示位置信息\n",
        "# pos表示每个单词在句子中的位置\n",
        "# 2i表示在词特征向量embedding中的位置\n",
        "# 例如embedding大小是300\n",
        "# i=0 时 2i=0 表示embedding的第一个位置 偶数位\n",
        "# 2i+1=1 表示embedding的第二个位置 奇数位\n",
        "# i=1 时 2i=2 表示embedding的第三个位置\n",
        "# 2i+1=3 表示embedding的第四个位置\n",
        "# 在2i=偶数时我们用sin， 2i+1=奇数时我们用cos\n",
        "# d_model 就是我们embedding得维度大小(例如300）\n",
        "# 简而言之，每个单词特征向量embedding的偶数位置元素用正弦函数计算\n",
        "# 奇数位子元素用余弦函数计算。\n",
        "\n",
        "# 计算公式。这里是上图中sin和cos中的（）括号部分\n",
        "def get_angles(pos, i, d_model):\n",
        "    angle_rates = 1/np.power(10000, (2 * (i//2)) / np.float32(d_model)) #i//2取整\n",
        "    return pos * angle_rates\n",
        "\n",
        "\n",
        "#position 表示句子的长度， d_model表示embedding维度的大小\n",
        "def positional_encoding(position, d_model):\n",
        "\n",
        "    angle_rads = get_angles(np.arange(position)[:, np.newaxis],\n",
        "                            np.arange(d_model)[np.newaxis, :],\n",
        "                            d_model)\n",
        "\n",
        "    # apply sin to even indices in the array; 2i\n",
        "    # 对数组中的偶数下标应用sin\n",
        "    angle_rads[:, 0::2] = np.sin(angle_rads[:, 0::2])\n",
        "\n",
        "    # apply cos to odd indices in the array; 2i+1\n",
        "    # 对数组中的奇数下标应用cos\n",
        "    angle_rads[:, 1::2] = np.cos(angle_rads[:, 1::2])\n",
        "\n",
        "    pos_encoding = angle_rads[np.newaxis, ...] #(1, position, d_model)\n",
        "\n",
        "    return tf.cast(pos_encoding, dtype=tf.float32) #把数据变成float32"
      ],
      "metadata": {
        "id": "KEJOo5OV2HtY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_padding_mask(seq):\n",
        "    #seq 输入的一批经过数字化和padding处理后的句子，\n",
        "    #也就是前面我们经过input_text_processor处理过的句子\n",
        "\n",
        "    #tf.math.equal(x,y)\n",
        "    #表示当x里的数据和y的值相等久表示位true，否则表示位false\n",
        "    #tf.cast()转换数据类型\n",
        "    seq = tf.cast(tf.math.equal(seq, 0), tf.float32) #(batch_size, seq_len)\n",
        "\n",
        "    #增加新的维度到padding\n",
        "    #将填充添加到注意力的logits里\n",
        "    return seq[:, tf.newaxis, tf.newaxis, :] #(batch_size, 1, 1, seq_len)"
      ],
      "metadata": {
        "id": "shxQVTHC28-q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def create_look_ahead_mask(size):\n",
        "    #size 就是句子的长度\n",
        "\n",
        "    #tf.ones创建一个所有元素都设置为(1)的张量, 形状shape（size，size）\n",
        "    mask = 1 - tf.linalg.band_part(tf.ones((size,size)), -1, 0)\n",
        "    return mask #(seq_len, seq_len)"
      ],
      "metadata": {
        "id": "u_S_8kes3Drq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "tf.ones((5,5))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pa94Kc4IAsq0",
        "outputId": "f5729608-c371-4187-d998-91694766d8eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#tf.linalg.band_part(input, num_lower, num_upper) 保留非主对角线的元素，其余位置的元素替换为0\n",
        "#input: 输入的张量\n",
        "#num_lower：指定保留的主对角线下方的副对角线的数量，输入数值为负数时，表示下方的对角矩阵元素全部保留\n",
        "#num_upper：指定保留的主对角线上方的副对角线的数量，输入数值为负数时，表示上方的对角矩阵元素全部保留；\n",
        "tf.linalg.band_part(tf.ones((5, 5)), -1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZDhJ1y_IAvpX",
        "outputId": "20f2b546-d1b6-4862-8c81-ac2f402ac2eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 1., 0., 0., 0.],\n",
              "       [1., 1., 1., 0., 0.],\n",
              "       [1., 1., 1., 1., 0.],\n",
              "       [1., 1., 1., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num_lower, num_upper, 都为0时，只保留的主对角线上的值\n",
        "tf.linalg.band_part(tf.ones((5, 5)), 0, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ml8SAz8gA0OF",
        "outputId": "80ca4e66-9c15-4906-d244-f4a6b0278517"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0.],\n",
              "       [0., 1., 0., 0., 0.],\n",
              "       [0., 0., 1., 0., 0.],\n",
              "       [0., 0., 0., 1., 0.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num_lower,为1时，只保留的主对角线上的下方的一个值\n",
        "tf.linalg.band_part(tf.ones((5, 5)), 1, 0)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ddzgpY8eA12K",
        "outputId": "4ae23338-a777-4924-d5dc-7347ca06fd5c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[1., 0., 0., 0., 0.],\n",
              "       [1., 1., 0., 0., 0.],\n",
              "       [0., 1., 1., 0., 0.],\n",
              "       [0., 0., 1., 1., 0.],\n",
              "       [0., 0., 0., 1., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#num_upper,为1时，只保留的主对角线上的上方的一个值\n",
        "tf.linalg.band_part(tf.ones((5, 5)), 0, 1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0LKZEQO4A4mi",
        "outputId": "b9e6c4a3-fad6-481c-e60a-ee3e5eb02de8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[1., 1., 0., 0., 0.],\n",
              "       [0., 1., 1., 0., 0.],\n",
              "       [0., 0., 1., 1., 0.],\n",
              "       [0., 0., 0., 1., 1.],\n",
              "       [0., 0., 0., 0., 1.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 前瞻掩码 也可以叫 Sequence mask 它主要应用在decoder中\n",
        "# 因为解码时，我们是一个接着一个单词去预测的，当前的单词，应该\n",
        "# 不知道后面单词的信息。 在decoder中我们也是要进行self-attention\n",
        "# q, k, v 中是包含 整条句子信息的，所以我们不仅要去除padding信息\n",
        "# 还要去除 按时间顺序排列的 单词顺序。\n",
        "# temp1先创建一个前瞻掩码\n",
        "x = tf.random.uniform((3, 5)) # 这里我们假设有3个句子，它们的长度是5\n",
        "temp1 = create_look_ahead_mask(x.shape[1])\n",
        "temp1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QTZzQhzZA9Pa",
        "outputId": "a55c4ff4-d61b-4dca-ab3b-c89c95a46471"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5, 5), dtype=float32, numpy=\n",
              "array([[0., 1., 1., 1., 1.],\n",
              "       [0., 0., 1., 1., 1.],\n",
              "       [0., 0., 0., 1., 1.],\n",
              "       [0., 0., 0., 0., 1.],\n",
              "       [0., 0., 0., 0., 0.]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#temp2 我们在创建一个padding_mask\n",
        "x = tf.constant([[1, 3, 2, 3, 0], [5, 2, 3, 0, 0], [7, 8, 0, 0, 0 ]])\n",
        "temp2 = create_padding_mask(x)\n",
        "temp2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SkP-HShBNe2",
        "outputId": "56abfad6-a354-4fa8-e0cb-b53fbe52c65c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 1, 5), dtype=float32, numpy=\n",
              "array([[[[0., 0., 0., 0., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 0., 1., 1., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#让temp1和temp2合并，按元素返回 temp1和 temp2 的最大值\n",
        "sequence_mask = tf.maximum(temp2, temp1)\n",
        "sequence_mask"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wuC3PfZbBPJJ",
        "outputId": "edab4e2e-23b9-4e08-aad4-2d2c3349a019"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(3, 1, 5, 5), dtype=float32, numpy=\n",
              "array([[[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 0., 1.],\n",
              "         [0., 0., 0., 0., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.],\n",
              "         [0., 0., 0., 1., 1.]]],\n",
              "\n",
              "\n",
              "       [[[0., 1., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.],\n",
              "         [0., 0., 1., 1., 1.]]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def scaled_dot_product_attention(q, k, v, mask):\n",
        "    \"\"\"计算注意力权重。\n",
        "    q, k, v 必须具有匹配的前置维度。\n",
        "    k, v 必须有匹配的倒数第二个维度，例如：seq_len_k = seq_len_v。\n",
        "    虽然 mask 根据其类型（填充或前瞻）有不同的形状，\n",
        "    但是 mask 必须能进行广播转换以便求和。\n",
        "\n",
        "    参数:\n",
        "    q: 请求的形状 == (..., seq_len_q, depth)\n",
        "    k: 主键的形状 == (..., seq_len_k, depth)\n",
        "    v: 数值的形状 == (..., seq_len_v, depth_v)\n",
        "    mask: Float 张量，其形状能转换成\n",
        "          (..., seq_len_q, seq_len_k)。默认为None。\n",
        "\n",
        "    返回值:\n",
        "    输出，注意力权重\n",
        "    \"\"\"\n",
        "\n",
        "    # 这里 q, k, v, 的形状是(batch_size, num_heads, seq_len, depth)\n",
        "    # 这里的batch_size是每次输入的句子数，num_heads 就是多头的大小\n",
        "    # seq_len 就是句子的长度， seq_len_q, seq_len_k, seq_len_v\n",
        "    # 大小都是一样的，都等于 seq_len 也就是所有句子的最大长度。\n",
        "    # depth = embedding_dim // num_heads\n",
        "    # 例如 我们设置multi-head等于8也就是num_heads等于8\n",
        "    # embedding_dim等于512  depth = 512//8 取整 等于 64\n",
        "\n",
        "    # transpose_b=True 表示对k进行转制\n",
        "    # transpose_a=True 表示对q进行转制\n",
        "    # 这个公式就是上图的 q*k的转制\n",
        "    matmul_qk = tf.matmul(q, k, transpose_b=True) # （batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "    # scale matmul_qk\n",
        "    dk = tf.cast(tf.shape(k)[-1], tf.float32)\n",
        "    scaled_attention_logits = matmul_qk / tf.math.sqrt(dk)\n",
        "\n",
        "    # add the mask to the scaled tensor\n",
        "    if mask is not None:\n",
        "        scaled_attention_logits += (mask * -1e9)\n",
        "\n",
        "    # softmax is normalized on the last axis (seq_len_k) so that the scores\n",
        "    # add up to 1.\n",
        "    # softmax在最后一个轴(seq_len_k)上被归一化，这样分数加起来等于1。\n",
        "    attention_weights = tf.nn.softmax(scaled_attention_logits, axis=-1) # （batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "\n",
        "    #tf.matmul attention_weights乘以v\n",
        "    output = tf.matmul(attention_weights, v) # （batch_size, num_heads, seq_len_q, depth_v)\n",
        "\n",
        "    return output, attention_weights"
      ],
      "metadata": {
        "id": "ikouTvRTBSaW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(tf.keras.layers.Layer):\n",
        "\n",
        "    def __init__(self, d_model, num_heads): #这里我们假设 d_model=512, num_heads=8\n",
        "        super(MultiHeadAttention, self).__init__()\n",
        "        self.num_heads = num_heads\n",
        "        self.d_model = d_model\n",
        "\n",
        "        #assert断言函数\n",
        "        #断言函数是对表达式布尔值的判断，要求表达式计算值必须为真。可用于自动调试。\n",
        "        #如果表达式为假，触发异常；如果表达式为真，不执行任何操作。\n",
        "        #也就是d_model能被num_heads 整除 余数为零 就不会报错，否则就会报错\n",
        "        assert d_model % self.num_heads == 0\n",
        "\n",
        "        self.depth = d_model // self.num_heads # depth=64\n",
        "\n",
        "        self.wq = tf.keras.layers.Dense(d_model)\n",
        "        self.wk = tf.keras.layers.Dense(d_model)\n",
        "        self.wv = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "        self.dense = tf.keras.layers.Dense(d_model)\n",
        "\n",
        "    def split_heads(self, x, batch_size): #这里我们假设batch_size=32, 这里x就是我的q,k,v shape都是(batch_size, seq_len, d_model)\n",
        "        \"\"\"Split the last dimension into (num_heads, depth).\n",
        "        Transpose the result such that the shape is (batch_size, num_heads, seq_len, depth)\n",
        "        \"\"\"\n",
        "        '''分拆最后一个维度到(num_heads, depth)\n",
        "        转置结果使得形状为(batch_size, num_heads, seq_len, depth)\n",
        "        '''\n",
        "        x = tf.reshape(x, (batch_size, -1, self.num_heads, self.depth)) # 这里的-1, 表示在这个维度上的数值进行自适应 x shape(32, 40, 8, 64)\n",
        "        return tf.transpose(x, perm=[0, 2, 1, 3]) #这里的prem=[0,2,1,3] 就是x shape按照索引id重新排列shape 最后x shape（32, 8, 40, 64)\n",
        "\n",
        "    def call(self, v, k, q, mask):\n",
        "        batch_size = tf.shape(q)[0]\n",
        "\n",
        "        q = self.wq(q)  # (batch_size, seq_len, d_model)\n",
        "        k = self.wk(k)  # (batch_size, seq_len, d_model)\n",
        "        v = self.wv(v)  # (batch_size, seq_len, d_model)\n",
        "\n",
        "        q = self.split_heads(q, batch_size)  # (batch_size, num_heads, seq_len_q, depth)\n",
        "        k = self.split_heads(k, batch_size)  # (batch_size, num_heads, seq_len_k, depth)\n",
        "        v = self.split_heads(v, batch_size)  # (batch_size, num_heads, seq_len_v, depth)\n",
        "\n",
        "        # scaled_attention.shape == (batch_size, num_heads, seq_len_q, depth)\n",
        "        # attention_weights.shape == (batch_size, num_heads, seq_len_q, seq_len_k)\n",
        "        scaled_attention, attention_weights = scaled_dot_product_attention(\n",
        "            q, k, v, mask)\n",
        "\n",
        "        scaled_attention = tf.transpose(scaled_attention, perm=[0, 2, 1, 3])  # (batch_size, seq_len_q, num_heads, depth)\n",
        "\n",
        "        concat_attention = tf.reshape(scaled_attention,\n",
        "                                      (batch_size, -1, self.d_model))  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        output = self.dense(concat_attention)  # (batch_size, seq_len_q, d_model)\n",
        "\n",
        "        return output, attention_weights\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "mEFMMkzJBXdn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这里我们要注意 d_model一定要能被num_heads整除，\n",
        "temp_mha = MultiHeadAttention(d_model=512, num_heads=8)\n",
        "y = tf.random.uniform((32, 60, 512))  # (batch_size, encoder_sequence, d_model)\n",
        "out, attn= temp_mha(y, k=y, q=y, mask=None)\n",
        "out.shape, attn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sjdgQYpfl3tT",
        "outputId": "07798cc4-afbe-4dfd-a2d6-35b3b30ad927"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([32, 60, 512]), TensorShape([32, 8, 60, 60]))"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 下面我们来实现上图，并得到结果Z\n",
        "# 为了简便我们就假设有2个头\n",
        "x = tf.random.normal([2,4])\n",
        "\n",
        "wq0 = tf.random.normal([4,3])\n",
        "wk0 = tf.random.normal([4,3])\n",
        "wv0 = tf.random.normal([4,3])\n",
        "print(wq0)\n",
        "print(wk0)\n",
        "print(wv0)\n",
        "\n",
        "wq1 = tf.random.normal([4,3])\n",
        "wk1 = tf.random.normal([4,3])\n",
        "wv1 = tf.random.normal([4,3])\n",
        "print(wq1)\n",
        "print(wk1)\n",
        "print(wv1)\n",
        "\n",
        "q0 = tf.matmul(x, wq0)\n",
        "k0 = tf.matmul(x, wk0)\n",
        "v0 = tf.matmul(x, wv0)\n",
        "print(q0)\n",
        "print(k0)\n",
        "print(v0)\n",
        "\n",
        "q1 = tf.matmul(x, wq1)\n",
        "k1 = tf.matmul(x, wk1)\n",
        "v1 = tf.matmul(x, wv1)\n",
        "print(q1)\n",
        "print(k1)\n",
        "print(v1)\n",
        "\n",
        "#上面求出了q0,q1,k0,k1,v0,v1.我们进行self-attention计算\n",
        "score0 = tf.matmul(q0, k0, transpose_b=True)\n",
        "score1 = tf.matmul(q1, k1, transpose_b=True)\n",
        "divide0 = score0/tf.sqrt(2.)\n",
        "divide1 = score1/tf.sqrt(2.)\n",
        "softmax0 = tf.nn.softmax(divide0)\n",
        "softmax1 = tf.nn.softmax(divide1)\n",
        "z0 = tf.matmul(softmax0, v0)\n",
        "z1 = tf.matmul(softmax1, v1)\n",
        "concat_z0_z1 = tf.concat([z0, z1], axis=1)\n",
        "wo = tf.random.normal([6, 4])\n",
        "Z = tf.matmul(concat_z0_z1, wo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0imVEuBKzWi1",
        "outputId": "c0ae1721-95a8-40cf-8bb3-678e6844040e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[[-0.88472116  1.1889303  -1.3843219 ]\n",
            " [-0.25823304  1.0580262  -0.58711296]\n",
            " [-1.268608    1.9998724  -0.14825355]\n",
            " [-0.08198109 -1.3427122  -0.03299769]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.2463899  -1.5258039  -1.3082879 ]\n",
            " [-0.32726452  0.23859227  0.9033423 ]\n",
            " [ 1.4620664  -1.546654   -0.49284947]\n",
            " [-0.24447066 -0.41563722 -0.02417343]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.3123093   0.34604782  0.29262528]\n",
            " [ 1.888671    2.7248647   0.3364324 ]\n",
            " [ 0.46097857  2.2128384  -0.16232409]\n",
            " [ 0.53796446  0.3603332  -2.6946707 ]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.14199163  0.90769166 -1.8983228 ]\n",
            " [-0.5070021   0.0389047   0.6544329 ]\n",
            " [ 1.1302539  -0.24819015 -0.8122715 ]\n",
            " [ 1.1507844   1.0083728  -1.0151385 ]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-3.286333    0.15751457  0.29308948]\n",
            " [ 1.344882   -0.25873023 -0.21951552]\n",
            " [-0.5410542  -0.3939255  -0.18509476]\n",
            " [-0.10313699 -0.6115892   0.337824  ]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 1.691777    0.09875561 -0.04653813]\n",
            " [-1.9785712   0.18874508 -0.6653819 ]\n",
            " [ 0.39287975 -1.2490511   0.6957843 ]\n",
            " [ 1.162597   -2.851614   -0.33395684]], shape=(4, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-0.92281395  3.284948   -1.6562696 ]\n",
            " [ 2.591664   -7.772053    3.9980335 ]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 2.0221238 -1.361547  -1.8785222]\n",
            " [-3.0929549  2.5294864  1.3835179]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.48212045 -0.8223137   4.4417872 ]\n",
            " [-5.1539183  -5.4049926  -6.6748214 ]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-1.5225173  -0.32459736 -1.0773404 ]\n",
            " [ 2.570263    0.10014963  1.1674781 ]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[-4.4898515   1.2246869  -0.06592703]\n",
            " [ 4.7692523  -1.0235933   0.4905913 ]], shape=(2, 3), dtype=float32)\n",
            "tf.Tensor(\n",
            "[[ 0.89464474  4.519347    0.5549365 ]\n",
            " [ 1.9989429  -5.983565    0.35228366]], shape=(2, 3), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def point_wise_feed_forward_network(d_model, dff):\n",
        "    #d_model 就是我们的embedding的深度\n",
        "    #dff 也就是我们要扩大的神经元个数\n",
        "    return tf.keras.Sequential([\n",
        "        tf.keras.layers.Dense(dff, activation='relu'), #(batch_size, seq_len, dff)\n",
        "        tf.keras.layers.Dense(d_model) #(batch_size, seq_len, d_model)\n",
        "    ])"
      ],
      "metadata": {
        "id": "Qi3bIJCg42wR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class EncoderLayer(tf.keras.layers.Layer):\n",
        "    # d_model embedding的维度数，这里我们设置为512\n",
        "    # num_heads 多头注意力的多头数，这里我们设置为8\n",
        "    # dff 在进行feed_forward 增加非线性时设置的神经元个数，这里我们设置为2048\n",
        "    # rate 防止过拟合我们加入了dropout，rate时dropout率\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(EncoderLayer, self).__init__()\n",
        "\n",
        "        self.mha = MultiHeadAttention(d_model, num_heads) #多头注意力\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff) #前馈网络增加非线性\n",
        "\n",
        "        #层标准化\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        #dropout层\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        # x.shape (batch_size, input_seq_len, d_model)\n",
        "        # training的值，我们这里设置为true或false\n",
        "        # dropout层 在training设置true时才适用，以便在推理\n",
        "        # 过程中不会丢失任何值。使用时model.fit, training将\n",
        "        # 自动适当地设置为true，\n",
        "        # 在其它上下文中，你可以在调用层时将kwarg显示设置为true\n",
        "        # mask 主要是来设置是padding mask还是 前瞻mask\n",
        "\n",
        "        #获得多头注意力\n",
        "        attn_output, _ = self.mha(x, x, x, mask) #(batch_size, input_seq_len, d_model)\n",
        "        #增加dropout层\n",
        "        attn_output = self.dropout1(attn_output, training=training)\n",
        "        #加入x进行残差计算，并进行层归一化\n",
        "        out1 = self.layernorm1(x + attn_output) #(batch_size, input_seq_len, d_model)\n",
        "\n",
        "        #进行前馈网络增加非线性\n",
        "        ffn_output = self.ffn(out1) #(batch_size, input_seq_len, d_model)\n",
        "        #增加dropout层\n",
        "        ffn_output = self.dropout2(ffn_output, training=training)\n",
        "        #加入out1进行残差计算，并进行层归一化\n",
        "        out2 = self.layernorm2(out1 + ffn_output) #(batch_size, input_seq_len, d_model)\n",
        "\n",
        "        return out2\n"
      ],
      "metadata": {
        "id": "Iz5Y3KsC42qK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 测试encoderlayer类\n",
        "# 进行类初始化\n",
        "sample_encoder_layer = EncoderLayer(512, 8, 2048)\n",
        "\n",
        "#调用call方法\n",
        "sample_encoder_layer_output = sample_encoder_layer(\n",
        "    tf.random.uniform((64, 43, 512)), False, None)\n",
        "\n",
        "sample_encoder_layer_output.shape  # (batch_size, input_seq_len, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZK_Z0Bir42in",
        "outputId": "1b4bfa07-23dc-4f30-a4bd-de0b09c6a698"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 43, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class DecoderLayer(tf.keras.layers.Layer):\n",
        "    # d_model embedding的维度数，这里我们设置为512\n",
        "    # num_heads 多头注意力力的多头数，这里我们设置为8\n",
        "    # dff 在进行feed_forward 增加非线性时设置的神经元个数，这里我们设置为2048\n",
        "    # rate 防止过拟合我们加入了dropout， rate是dropout率\n",
        "    def __init__(self, d_model, num_heads, dff, rate=0.1):\n",
        "        super(DecoderLayer, self).__init__()\n",
        "\n",
        "        #多头注意力，这是第一个多头注意力，是decoder部分的自己的多头注意力\n",
        "        self.mha1 = MultiHeadAttention(d_model, num_heads)\n",
        "        #这个多头注意力，是encoder的输出和上面decoder多头注意力输出进行组合后的多头注意力\n",
        "        self.mha2 = MultiHeadAttention(d_model, num_heads)\n",
        "\n",
        "        #前馈网络增加非线性\n",
        "        self.ffn = point_wise_feed_forward_network(d_model, dff)\n",
        "\n",
        "        #层标准化\n",
        "        self.layernorm1 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm2 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "        self.layernorm3 = tf.keras.layers.LayerNormalization(epsilon=1e-6)\n",
        "\n",
        "        self.dropout1 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout2 = tf.keras.layers.Dropout(rate)\n",
        "        self.dropout3 = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        # enc_output.shape == (batch_size, input_seq_len, d_model)\n",
        "\n",
        "        #下面3行诗decoder解码器的 attention，残差， layernorm，也就是上图解码器中的第一个mha部分红框部分\n",
        "        attn1, attn_weights_block1 = self.mha1(x, x, x, look_ahead_mask) #(batch_size, target_seq_len, d_model)\n",
        "        attn1 = self.dropout1(attn1, training=training)\n",
        "        out1 = self.layernorm1(attn1 + x)\n",
        "\n",
        "        #编码器和解码器之间的attention 也就是上图蓝框的attention部分\n",
        "        #这里我们可以看到mha2的其中2个x 是enc_output, 一个x是上面decoder的out1\n",
        "        #(batch_size, target_seq_len, d_model)\n",
        "        attn2, attn_weights_block2 = self.mha2(enc_output, enc_output, out1, padding_mask)\n",
        "        attn2 = self.dropout2(attn2, training=training)\n",
        "        out2 = self.layernorm2(attn2 + out1)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        #进行前馈网络增加非线性,增加dropout层,进行残差计算，并进行层归一化\n",
        "        #这部分对应上图decoder部分的最上面的绿框部分\n",
        "        ffn_output = self.ffn(out2)  # (batch_size, target_seq_len, d_model)\n",
        "        ffn_output = self.dropout3(ffn_output, training=training)\n",
        "        out3 = self.layernorm3(ffn_output + out2)  # (batch_size, target_seq_len, d_model)\n",
        "\n",
        "        return out3, attn_weights_block1, attn_weights_block2\n"
      ],
      "metadata": {
        "id": "8T0wWVp1APZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder_layer = DecoderLayer(512, 8, 2048)\n",
        "\n",
        "sample_decoder_layer_output, _, _ = sample_decoder_layer(\n",
        "    tf.random.uniform((64, 50, 512)), sample_encoder_layer_output,\n",
        "    False, None, None)\n",
        "\n",
        "sample_decoder_layer_output.shape  # (batch_size, target_seq_len, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i3AWer6KAPWd",
        "outputId": "8070e874-806e-4419-d067-64954dec81d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([64, 50, 512])"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Encoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                 maximum_position_encoding, rate=0.1):\n",
        "        super(Encoder, self).__init__()\n",
        "        #num_layers, 表示encoderlayer部件要有几个\n",
        "        #d_model, 表示embedding的深度是多少\n",
        "        #num_heads 表示多头注意力里面的多头数是多少\n",
        "        #dff 表示增加非线性时设置的神经元个数\n",
        "        #input_vocab_size 输入的词典大小\n",
        "        #maximum_position_encoding 最大句子的长度 这里是输入句子的最大长度\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        #embedding操作\n",
        "        self.embedding = tf.keras.layers.Embedding(input_vocab_size, d_model)\n",
        "        #位置编码\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, self.d_model)\n",
        "\n",
        "        #这里我们用一个列表先初始化num_layers个EncoderLayer类，好用来调用\n",
        "        self.enc_layers = [EncoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, training, mask):\n",
        "        seq_len = tf.shape(x)[1] #这里取得句子的最大长度，是为后面的位置信息作准备的。\n",
        "\n",
        "        #将给每个单词加入嵌入信息\n",
        "        x = self.embedding(x) #(batch_size, input_seq_len, d_model)\n",
        "        #这里x在乘以d_moder的平方根是为了增强语意信息，而弱化后面要加入的位置信息\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        #虽然上面的pos_encoding里的maximum_position_encoding我们取的值很大\n",
        "        #例如maximum_position_encoding等于10000，但是下面的seq_len截断到了句子的长度\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        #对EncoderLayer进行num_layers次循环\n",
        "        #同时每次循环都取self.enc_layers[i]进行初始化\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.enc_layers[i](x, training, mask)\n",
        "\n",
        "        return x #(batch_size, input_seq_len, d_model)\n"
      ],
      "metadata": {
        "id": "mgFyyyr1APTw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_encoder = Encoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, input_vocab_size=8500,\n",
        "                         maximum_position_encoding=10000)\n",
        "temp_input = tf.random.uniform((64, 62), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "sample_encoder_output = sample_encoder(temp_input, training=False, mask=None)\n",
        "\n",
        "print(sample_encoder_output.shape)  # (batch_size, input_seq_len, d_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cXTNEiQaAPRL",
        "outputId": "15aa1370-cc49-489b-9ff4-409dee419755"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 62, 512)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Decoder(tf.keras.layers.Layer):\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, target_vocab_size,\n",
        "                 maximum_position_encoding, rate=0.1):\n",
        "        super(Decoder, self).__init__()\n",
        "        #num_layers, 表示decodrlayer部件要有几个\n",
        "        #d_model, 表示embedding的深度是多少\n",
        "        #num_heads 表示多头注意力里面的多头数是多少\n",
        "        #dff 表示增加非线性时设置的神经元个数\n",
        "        #target_vocab_size 输出的词典大小\n",
        "        #maximum_position_encoding 最大句子的长度 这里是输出句子的最大长度\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.num_layers = num_layers\n",
        "\n",
        "        #embedding操作\n",
        "        self.embedding = tf.keras.layers.Embedding(target_vocab_size, d_model)\n",
        "        #位置编码\n",
        "        self.pos_encoding = positional_encoding(maximum_position_encoding, d_model)\n",
        "\n",
        "        #这里我们用一个列表先初始化num_layers个DecoderLayer类，好用来调用\n",
        "        self.dec_layers = [DecoderLayer(d_model, num_heads, dff, rate) for _ in range(num_layers)]\n",
        "\n",
        "        self.dropout = tf.keras.layers.Dropout(rate)\n",
        "\n",
        "    def call(self, x, enc_output, training, look_ahead_mask, padding_mask):\n",
        "        #enc_output 就是上面encoder输出，如上图蓝框的部分，我们需要用到encoder输出\n",
        "        #look_ahead_mask 前瞻掩码\n",
        "\n",
        "        seq_len = tf.shape(x)[1] #这个seq_len就是target_seq_len\n",
        "        attention_weights = {}\n",
        "\n",
        "        #将给每个单词加入嵌入信息\n",
        "        x = self.embedding(x) #(batch_size, target_seq_len, d_model)\n",
        "        #这里x在乘以d_moder的平方根是为了增强语意信息，而弱化后面要加入的位置信息\n",
        "        x *= tf.math.sqrt(tf.cast(self.d_model, tf.float32))\n",
        "        #虽然上面的pos_encoding里的maximum_position_encoding我们取的值很大\n",
        "        #例如maximum_position_encoding等于10000，但是下面的seq_len截断到了句子的长度\n",
        "        x += self.pos_encoding[:, :seq_len, :]\n",
        "\n",
        "        x = self.dropout(x, training=training)\n",
        "\n",
        "        #对decoderLayer进行num_layers次循环\n",
        "        #同时每次循环都取self.dec_layers[i]进行初始化\n",
        "        for i in range(self.num_layers):\n",
        "            x, block1, block2 = self.dec_layers[i](x, enc_output, training, look_ahead_mask, padding_mask)\n",
        "\n",
        "            attention_weights[f'decoder_layer{i+1}_block1'] = block1\n",
        "            attention_weights[f'decoder_layer{i+1}_block2'] = block2\n",
        "\n",
        "        #x.shape == (batch_size, target_seq_len, d_model)\n",
        "        return x, attention_weights"
      ],
      "metadata": {
        "id": "IgHlIuSmAdFt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_decoder = Decoder(num_layers=2, d_model=512, num_heads=8,\n",
        "                         dff=2048, target_vocab_size=8000,\n",
        "                         maximum_position_encoding=5000)\n",
        "temp_input = tf.random.uniform((64, 26), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "output, attn = sample_decoder(temp_input,\n",
        "                              enc_output=sample_encoder_output,\n",
        "                              training=False,\n",
        "                              look_ahead_mask=None,\n",
        "                              padding_mask=None)\n",
        "\n",
        "output.shape, attn['decoder_layer2_block2'].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mYN_rkLDAe-a",
        "outputId": "372dfb48-fbb6-41ee-fff4-5cd3b53120fb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([64, 26, 512]), TensorShape([64, 8, 26, 62]))"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Transformer(tf.keras.Model):\n",
        "    #num_layers, 表示decodrlayer部件要有几个\n",
        "    #d_model, 表示embedding的深度是多少\n",
        "    #num_heads 表示多头注意力里面的多头数是多少\n",
        "    #dff 表示增加非线性时设置的神经元个数\n",
        "    #input_vocab_size 输入的词典大小\n",
        "    #target_vocab_size 输出的词典大小\n",
        "    #这里的pe_input 就是前面的maximum_position_encoding 最大句子的长度 这里是输入句子的最大长度\n",
        "    #这里的pe_target 就是前面的maximum_position_encoding 最大句子的长度 这里是输出句子的最大长度\n",
        "\n",
        "    def __init__(self, num_layers, d_model, num_heads, dff, input_vocab_size,\n",
        "                 target_vocab_size, pe_input, pe_target, rate=0.1):\n",
        "\n",
        "        super().__init__()\n",
        "\n",
        "        #transformer中的encoder部分也就是上图左半部分\n",
        "        self.encoder = Encoder(num_layers, d_model, num_heads, dff, input_vocab_size, pe_input, rate)\n",
        "        #transformer中的decoder部分也就是上图右半部分\n",
        "        self.decoder = Decoder(num_layers, d_model, num_heads, dff, target_vocab_size, pe_target, rate)\n",
        "        #全链接层\n",
        "        self.final_layer = tf.keras.layers.Dense(target_vocab_size)\n",
        "\n",
        "    def call(self, inputs, training):\n",
        "        # Keras models prefer if you pass all your inputs in the first argument\n",
        "        # Keras模型更喜欢在第一个参数中传递所有的输入\n",
        "        inp, tar = inputs\n",
        "\n",
        "        #下面会创建一个create_masks方法，这里我们调用create_masks方法\n",
        "        enc_padding_mask, look_ahead_mask, dec_padding_mask = self.create_masks(inp, tar)\n",
        "\n",
        "        enc_output = self.encoder(inp, training, enc_padding_mask) #(batch_size, inp_seq_len, d_model)\n",
        "\n",
        "        # dec_output.shape == (batch_size, tar_seq_len, d_model)\n",
        "        dec_output, attention_weights = self.decoder(\n",
        "            tar, enc_output, training, look_ahead_mask, dec_padding_mask)\n",
        "\n",
        "        final_output = self.final_layer(dec_output) #(batch_size, tar_seq_len, target_vocab_size)\n",
        "\n",
        "        return final_output, attention_weights\n",
        "\n",
        "    def create_masks(self, inp, tar):\n",
        "        #Encoder padding mask\n",
        "        enc_padding_mask = create_padding_mask(inp) #（batch_size, 1, 1, inp_seq_len)\n",
        "\n",
        "        #Used in the 2nd attention block in the decoder.\n",
        "        #This padding mask is used to mask the encoder outputs.\n",
        "        #用于解码器的第二个注意块。\n",
        "        #这个填充掩码是用来掩码编码器输出的。\n",
        "        #在解码器的第二个注意力模块使用\n",
        "        #该填充遮挡用于遮挡编码器的输出\n",
        "        dec_padding_mask = create_padding_mask(inp) #（batch_size, 1, 1, inp_seq_len)\n",
        "\n",
        "        # Used in the 1st attention block in the decoder.\n",
        "        # It is used to pad and mask future tokens in the input received by\n",
        "        # the decoder.\n",
        "        #用于解码器的第一个注意块。\n",
        "        #它用于填充和掩码未来的令牌接收的输入\n",
        "        #解码器。\n",
        "        look_ahead_mask = create_look_ahead_mask(tf.shape(tar)[1]) #(tar_seq_len, tar_seq_len)\n",
        "        dec_target_padding_mask = create_padding_mask(tar) #(batch_size, 1, 1, tar_seq_len)\n",
        "        #tf.maximum(x,y) 按元素返回 x 和 y 的最大值\n",
        "        look_ahead_mask = tf.maximum(dec_target_padding_mask, look_ahead_mask) #（batch_size, 1, tar_seq_len, tar_seq_len)\n",
        "\n",
        "        return enc_padding_mask, look_ahead_mask, dec_padding_mask\n"
      ],
      "metadata": {
        "id": "yqIcIbflAnIX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample_transformer = Transformer(\n",
        "    num_layers=2, d_model=512, num_heads=8, dff=2048,\n",
        "    input_vocab_size=8500, target_vocab_size=8000,\n",
        "    pe_input=10000, pe_target=6000)\n",
        "\n",
        "temp_input = tf.random.uniform((1, 38), dtype=tf.int64, minval=0, maxval=200)\n",
        "temp_target = tf.random.uniform((1, 4), dtype=tf.int64, minval=0, maxval=200)\n",
        "\n",
        "fn_out, _ = sample_transformer([temp_input, temp_target], training=False)\n",
        "\n",
        "fn_out.shape  # (batch_size, tar_seq_len, target_vocab_size)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yy5mgKzXApVT",
        "outputId": "aa43c679-1edc-4961-d061-4fb83e932457"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TensorShape([1, 4, 8000])"
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "num_layers = 4\n",
        "d_model = 128\n",
        "dff = 512\n",
        "num_heads = 8\n",
        "dropout_rate = 0.1"
      ],
      "metadata": {
        "id": "c_5E1unpCWpp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomSchedule(tf.keras.optimizers.schedules.LearningRateSchedule):\n",
        "    def __init__(self, d_model, warmup_steps=4000):\n",
        "        super(CustomSchedule, self).__init__()\n",
        "\n",
        "        self.d_model = d_model\n",
        "        self.d_model = tf.cast(self.d_model, tf.float32)\n",
        "\n",
        "        self.warmup_steps = warmup_steps\n",
        "\n",
        "    def __call__(self, step):\n",
        "        step = tf.cast(step, tf.float32)  # 确保 step 是 float32 类型\n",
        "        #这里的step就是上面公式的step_num, 进行平方根的倒数, arg1是一个逐渐减小的数值\n",
        "        arg1 = tf.math.rsqrt(step)\n",
        "        #arg2是一个逐渐增大的数值\n",
        "        arg2 = step * (self.warmup_steps ** -1.5)\n",
        "\n",
        "        #开始arg1大于arg2 在达到warmup_steps(4000)轮次时，arg1和arg2的值相等，4001时arg1小于arg2\n",
        "        #tf.math.minimum(x, y)按元素返回 x 和 y 的最小值\n",
        "        return tf.math.rsqrt(self.d_model) * tf.math.minimum(arg1, arg2)"
      ],
      "metadata": {
        "id": "fZJ8fUohCbzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "temp_learning_rate_scheldule = CustomSchedule(d_model)\n",
        "\n",
        "plt.plot(temp_learning_rate_scheldule(tf.range(40000, dtype=tf.float32)))\n",
        "plt.ylabel(\"Learning Rate\")\n",
        "plt.xlabel(\"Train Step\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 466
        },
        "id": "YNRHsy-mCdO_",
        "outputId": "d9b6f12f-5488-4490-b078-8ae6b80bcfe5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Text(0.5, 0, 'Train Step')"
            ]
          },
          "metadata": {},
          "execution_count": 53
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "learning_rate = CustomSchedule(d_model)\n",
        "#这里我们使用adam优化器,并使用我们自定义的学习率\n",
        "optimizer = tf.keras.optimizers.Adam(learning_rate, beta_1=0.9, beta_2=0.98, epsilon=1e-9)\n"
      ],
      "metadata": {
        "id": "8X3RQXSLCfBi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#这里我们使用稀疏交叉熵损失函数\n",
        "#from_logits: 为True时，会将y_pred转化为概率（用softmax）,否则不进行转换，通常情况下用True结果更稳定；\n",
        "#reduction：类型为tf.keras.losses.Reduction，对loss进行处理，默认是求平均；\n",
        "#这里我们设置为none不进行自动求平均处理，我门后面要定义一个方法去求平均\n",
        "loss_object = tf.keras.losses.SparseCategoricalCrossentropy(\n",
        "    from_logits=True, reduction='none')"
      ],
      "metadata": {
        "id": "AEYFKc_SCnY-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def loss_function(real, pred):\n",
        "    #real 真实值 shape （batch_size, target_seq_len)\n",
        "    #这里的target_seq_len 要去掉句子开头的start, 所以实际长度要减一\n",
        "    #pred 预测值 shape （batch_size, tar_seq_len, target_vocab_size)\n",
        "    #预测值里的tar_seq_len是没有start的，因为start是作为预测的输入，\n",
        "    #而输出是start后面的第一个单词\n",
        "\n",
        "    #tf.math.equal(real,0) 表示real里面是0的值表示为true，不是零的表示为false\n",
        "    #tf.math.logical_not(tf.math.equal(real, 0)) 是把true改成false， false改成true\n",
        "    mask = tf.math.logical_not(tf.math.equal(real, 0))\n",
        "\n",
        "    #求损失\n",
        "    loss_ = loss_object(real, pred)\n",
        "\n",
        "    #转换数据类型（就是true变成1，false变成0）\n",
        "    mask = tf.cast(mask, dtype=loss_.dtype)\n",
        "\n",
        "    #去掉mask对应的值,\n",
        "    #就是loss位置对应的值和mask对应的位置相乘，mask对应是0的位置loss值也会变成零\n",
        "    loss_ *= mask\n",
        "\n",
        "    #求loss平均值\n",
        "    return tf.reduce_sum(loss_)/tf.reduce_sum(mask)"
      ],
      "metadata": {
        "id": "HEWS8zRdCpNx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def accuracy_function(real, pred):\n",
        "    #real (batch_size, target_seq_len) 这里的target_seq_len长度根上面loss的real长度一样\n",
        "    #pred (batch_size, tar_seq_len, target_vocab_size)\n",
        "    #这里的tar_seq_len和target_seq_len大小是相等的。\n",
        "\n",
        "    #tf.argmax 取pred里的最大值，axis=2 表示取第3个维度target_vocab_size里的最大值\n",
        "    #最后shape为（batch_size, tar_seq_len)\n",
        "    #tf.equal 就是拿real和刚取了最大值的pred进行比较\n",
        "    #值相等的单词就是true 否则为false\n",
        "    accuracies = tf.equal(real, tf.argmax(pred, axis=2))\n",
        "\n",
        "    #tf.math.equal(real,0) 表示real里面是0的值表示为true，不是零的表示为false\n",
        "    #tf.math.logical_not(tf.math.equal(real, 0)) 是把true改成false， false改成true\n",
        "    #mask表示 real里单词不是0的是true， 是零的false\n",
        "    mask = tf.math.logical_not(tf.math.equal(real,0))\n",
        "\n",
        "    #表示mask和accuracies相同就用true不同就false\n",
        "    accuracies = tf.math.logical_and(mask, accuracies)\n",
        "\n",
        "    accuracies = tf.cast(accuracies, dtype=tf.float32)\n",
        "    mask = tf.cast(mask, dtype=tf.float32)\n",
        "\n",
        "    #tf.reduce_sum(accuracies)是求有多少个预测正确的单词\n",
        "    #tf.reduce_sum(mask)是求总共有多少单词。\n",
        "    return tf.reduce_sum(accuracies)/tf.reduce_sum(mask)\n",
        "\n",
        "# loss 和 accuracy 使用上面自定义的 loss和 accuracy\n",
        "train_loss = tf.keras.metrics.Mean(name='train_loss')\n",
        "train_accuracy = tf.keras.metrics.Mean(name='train_accuracy')"
      ],
      "metadata": {
        "id": "1SZVyEcDCrD-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_text_processor.vocabulary_size()  #输入，中文单词的数量\n",
        "output_text_processor.vocabulary_size() #输出，英文单词的数量\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jq-uD8odCu6_",
        "outputId": "d8f6ed49-7fbf-469d-e1b3-c7855f6e6eda"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "7180"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#初始化Transformer类\n",
        "#num_layers, 表示decodrlayer部件要有几个\n",
        "#d_model, 表示embedding的深度是多少\n",
        "#num_heads 表示多头注意力里面的多头数是多少\n",
        "#dff 表示增加非线性时设置的神经元个数\n",
        "#input_vocab_size 输入的词典大小\n",
        "#target_vocab_size 输出的词典大小\n",
        "#这里的pe_input 就是前面的maximum_position_encoding 最大句子的长度 这里是输入句子的最大长度\n",
        "#这里的pe_target 就是前面的maximum_position_encoding 最大句子的长度 这里是输出句子的最大长度\n",
        "\n",
        "transformer = Transformer(\n",
        "    num_layers=num_layers,\n",
        "    d_model=d_model,\n",
        "    num_heads=num_heads,\n",
        "    dff=dff,\n",
        "    input_vocab_size=input_text_processor.vocabulary_size(),\n",
        "    target_vocab_size=output_text_processor.vocabulary_size(),\n",
        "    pe_input=1000,\n",
        "    pe_target=1000,\n",
        "    rate=dropout_rate)"
      ],
      "metadata": {
        "id": "WaSn5GSYC1G_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_path = \"./checkpoints/cn_en/train\" #检测文件保存位置\n",
        "\n",
        "#检查点保存的内容\n",
        "ckpt = tf.train.Checkpoint(transformer=transformer,\n",
        "                           optimizer=optimizer)\n",
        "#max_to_keep=5 要保留的检查点的数\n",
        "ckpt_manager = tf.train.CheckpointManager(ckpt, checkpoint_path, max_to_keep=5)\n",
        "\n",
        "#下面的语句作用，如果检查点存在，则恢复最新的检查点\n",
        "if ckpt_manager.latest_checkpoint:\n",
        "    ckpt.restore(ckpt_manager.latest_checkpoint)\n",
        "    print('Latest checkpoint restored!!')"
      ],
      "metadata": {
        "id": "5M_lbcz2C1EU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20 #我们要进行20次循环训练，大家可以根据效果适当增加和减少\n"
      ],
      "metadata": {
        "id": "UV2Azw-JC1Bw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#定义一个train_step_signature列表\n",
        "#列表里含有2个被tf.TensorSpec定义的张量\n",
        "train_step_signature = [\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "    tf.TensorSpec(shape=(None, None), dtype=tf.int64),\n",
        "]\n",
        "train_step_signature"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NtAxuClQC8n0",
        "outputId": "c7b8af20-7878-42f1-f920-615ea301d8d7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[TensorSpec(shape=(None, None), dtype=tf.int64, name=None),\n",
              " TensorSpec(shape=(None, None), dtype=tf.int64, name=None)]"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#input_signature的好处：\n",
        "#1.可以限定函数的输入类型，以防止调用函数时调错，\n",
        "#2．一个函数有了input_signature之后，在tensorflow里边才可以保存成savedmodel。\n",
        "#在保存成savedmodel的过程中，需要使用get_concrete_function函数把一个tf.function\n",
        "#标注的普通的python函数变成带有图定义的函数。\n",
        "\n",
        "# tf.function 模块\n",
        "#我们仅需加入一个简单的 @tf.function 修饰符，就能轻松将模型以图模式运行！\n",
        "\n",
        "@tf.function(input_signature=train_step_signature)\n",
        "def train_step(inp, tar):\n",
        "    tar_inp = tar[:, :-1]\n",
        "    tar_real = tar[:, 1:]\n",
        "\n",
        "    #tf.GradientTape()计算梯度用的\n",
        "    with tf.GradientTape() as tape:\n",
        "        #先求出预测值\n",
        "        predictions, _ = transformer([inp, tar_inp], training=True)\n",
        "        #计算loss\n",
        "        loss = loss_function(tar_real, predictions)\n",
        "    #计算出所有可训练变量的梯度，然后进行下一步的更新\n",
        "    gradients = tape.gradient(loss, transformer.trainable_variables)\n",
        "    #优化，应用更新的梯度\n",
        "    optimizer.apply_gradients(zip(gradients, transformer.trainable_variables))\n",
        "\n",
        "    #应用自定义的 loss和 accuracy函数，求出loss和accuracy\n",
        "    train_loss(loss)\n",
        "    train_accuracy(accuracy_function(tar_real, predictions))"
      ],
      "metadata": {
        "id": "Zlq_7EaJC-1I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for epoch in range(EPOCHS): #进行20轮的训练\n",
        "    start = time.time()\n",
        "\n",
        "    #没轮开始前重新初始化loss和accuracy值\n",
        "    train_loss.reset_states()\n",
        "    train_accuracy.reset_states()\n",
        "\n",
        "    # inp -> China, tar -> english\n",
        "    for (batch, (inp, tar)) in enumerate(train_batches):\n",
        "        train_step(inp, tar)\n",
        "        #每50batch打印一次loss和accuray\n",
        "        if batch % 50 == 0:\n",
        "            print(f'Epoch {epoch + 1} Batch {batch} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    #每5个epoch保存一次检查点\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        ckpt_save_path = ckpt_manager.save()\n",
        "        print(f'Saving checkpoint for epoch {epoch+1} at {ckpt_save_path}')\n",
        "    #每个epoch完后打印一次loss和accuracy\n",
        "    print(f'Epoch {epoch + 1} Loss {train_loss.result():.4f} Accuracy {train_accuracy.result():.4f}')\n",
        "    #每个epoch完成后打印一次运行所用时间\n",
        "    print(f'Time taken for 1 epoch: {time.time() - start:.2f} secs\\n')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gfpv8XcRDAxA",
        "outputId": "1f0111c3-1bb2-448b-92b0-39c375d691ec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 8.9791 Accuracy 0.0000\n",
            "Epoch 1 Batch 50 Loss 8.8920 Accuracy 0.0012\n",
            "Epoch 1 Batch 100 Loss 8.7227 Accuracy 0.0575\n",
            "Epoch 1 Batch 150 Loss 8.5675 Accuracy 0.0788\n",
            "Epoch 1 Batch 200 Loss 8.3967 Accuracy 0.0897\n",
            "Epoch 1 Batch 250 Loss 8.1970 Accuracy 0.0961\n",
            "Epoch 1 Batch 300 Loss 7.9677 Accuracy 0.1097\n",
            "Epoch 1 Batch 350 Loss 7.7285 Accuracy 0.1254\n",
            "Epoch 1 Batch 400 Loss 7.4921 Accuracy 0.1380\n",
            "Epoch 1 Batch 450 Loss 7.2731 Accuracy 0.1499\n",
            "Epoch 1 Loss 7.2020 Accuracy 0.1536\n",
            "Time taken for 1 epoch: 81.27 secs\n",
            "\n",
            "Epoch 2 Batch 0 Loss 5.2868 Accuracy 0.2390\n",
            "Epoch 2 Batch 50 Loss 5.1355 Accuracy 0.2696\n",
            "Epoch 2 Batch 100 Loss 5.0314 Accuracy 0.2807\n",
            "Epoch 2 Batch 150 Loss 4.9417 Accuracy 0.2882\n",
            "Epoch 2 Batch 200 Loss 4.8641 Accuracy 0.2944\n",
            "Epoch 2 Batch 250 Loss 4.7913 Accuracy 0.3017\n",
            "Epoch 2 Batch 300 Loss 4.7254 Accuracy 0.3084\n",
            "Epoch 2 Batch 350 Loss 4.6664 Accuracy 0.3143\n",
            "Epoch 2 Batch 400 Loss 4.6083 Accuracy 0.3196\n",
            "Epoch 2 Batch 450 Loss 4.5520 Accuracy 0.3247\n",
            "Epoch 2 Loss 4.5335 Accuracy 0.3266\n",
            "Time taken for 1 epoch: 31.88 secs\n",
            "\n",
            "Epoch 3 Batch 0 Loss 4.0557 Accuracy 0.3930\n",
            "Epoch 3 Batch 50 Loss 3.9240 Accuracy 0.3813\n",
            "Epoch 3 Batch 100 Loss 3.9097 Accuracy 0.3826\n",
            "Epoch 3 Batch 150 Loss 3.8795 Accuracy 0.3845\n",
            "Epoch 3 Batch 200 Loss 3.8580 Accuracy 0.3863\n",
            "Epoch 3 Batch 250 Loss 3.8295 Accuracy 0.3888\n",
            "Epoch 3 Batch 300 Loss 3.8089 Accuracy 0.3905\n",
            "Epoch 3 Batch 350 Loss 3.7842 Accuracy 0.3928\n",
            "Epoch 3 Batch 400 Loss 3.7650 Accuracy 0.3944\n",
            "Epoch 3 Batch 450 Loss 3.7468 Accuracy 0.3965\n",
            "Epoch 3 Loss 3.7423 Accuracy 0.3971\n",
            "Time taken for 1 epoch: 31.19 secs\n",
            "\n",
            "Epoch 4 Batch 0 Loss 3.5215 Accuracy 0.4272\n",
            "Epoch 4 Batch 50 Loss 3.4551 Accuracy 0.4218\n",
            "Epoch 4 Batch 100 Loss 3.4297 Accuracy 0.4242\n",
            "Epoch 4 Batch 150 Loss 3.4197 Accuracy 0.4239\n",
            "Epoch 4 Batch 200 Loss 3.4084 Accuracy 0.4255\n",
            "Epoch 4 Batch 250 Loss 3.3947 Accuracy 0.4268\n",
            "Epoch 4 Batch 300 Loss 3.3810 Accuracy 0.4286\n",
            "Epoch 4 Batch 350 Loss 3.3661 Accuracy 0.4301\n",
            "Epoch 4 Batch 400 Loss 3.3556 Accuracy 0.4311\n",
            "Epoch 4 Batch 450 Loss 3.3435 Accuracy 0.4328\n",
            "Epoch 4 Loss 3.3405 Accuracy 0.4333\n",
            "Time taken for 1 epoch: 30.06 secs\n",
            "\n",
            "Epoch 5 Batch 0 Loss 3.0045 Accuracy 0.4720\n",
            "Epoch 5 Batch 50 Loss 3.0582 Accuracy 0.4589\n",
            "Epoch 5 Batch 100 Loss 3.0661 Accuracy 0.4597\n",
            "Epoch 5 Batch 150 Loss 3.0500 Accuracy 0.4624\n",
            "Epoch 5 Batch 200 Loss 3.0401 Accuracy 0.4633\n",
            "Epoch 5 Batch 250 Loss 3.0338 Accuracy 0.4633\n",
            "Epoch 5 Batch 300 Loss 3.0324 Accuracy 0.4639\n",
            "Epoch 5 Batch 350 Loss 3.0219 Accuracy 0.4653\n",
            "Epoch 5 Batch 400 Loss 3.0162 Accuracy 0.4661\n",
            "Epoch 5 Batch 450 Loss 3.0105 Accuracy 0.4669\n",
            "Saving checkpoint for epoch 5 at ./checkpoints/cn_en/train/ckpt-1\n",
            "Epoch 5 Loss 3.0046 Accuracy 0.4676\n",
            "Time taken for 1 epoch: 30.93 secs\n",
            "\n",
            "Epoch 6 Batch 0 Loss 2.8242 Accuracy 0.4960\n",
            "Epoch 6 Batch 50 Loss 2.7309 Accuracy 0.4928\n",
            "Epoch 6 Batch 100 Loss 2.7176 Accuracy 0.4961\n",
            "Epoch 6 Batch 150 Loss 2.7176 Accuracy 0.4963\n",
            "Epoch 6 Batch 200 Loss 2.7122 Accuracy 0.4977\n",
            "Epoch 6 Batch 250 Loss 2.7071 Accuracy 0.4994\n",
            "Epoch 6 Batch 300 Loss 2.7049 Accuracy 0.5002\n",
            "Epoch 6 Batch 350 Loss 2.6974 Accuracy 0.5012\n",
            "Epoch 6 Batch 400 Loss 2.6900 Accuracy 0.5026\n",
            "Epoch 6 Batch 450 Loss 2.6867 Accuracy 0.5038\n",
            "Epoch 6 Loss 2.6866 Accuracy 0.5040\n",
            "Time taken for 1 epoch: 30.20 secs\n",
            "\n",
            "Epoch 7 Batch 0 Loss 2.3271 Accuracy 0.5347\n",
            "Epoch 7 Batch 50 Loss 2.3837 Accuracy 0.5431\n",
            "Epoch 7 Batch 100 Loss 2.3854 Accuracy 0.5429\n",
            "Epoch 7 Batch 150 Loss 2.3910 Accuracy 0.5432\n",
            "Epoch 7 Batch 200 Loss 2.3867 Accuracy 0.5439\n",
            "Epoch 7 Batch 250 Loss 2.3862 Accuracy 0.5445\n",
            "Epoch 7 Batch 300 Loss 2.3862 Accuracy 0.5454\n",
            "Epoch 7 Batch 350 Loss 2.3859 Accuracy 0.5461\n",
            "Epoch 7 Batch 400 Loss 2.3846 Accuracy 0.5466\n",
            "Epoch 7 Batch 450 Loss 2.3835 Accuracy 0.5471\n",
            "Epoch 7 Loss 2.3825 Accuracy 0.5473\n",
            "Time taken for 1 epoch: 30.46 secs\n",
            "\n",
            "Epoch 8 Batch 0 Loss 2.1242 Accuracy 0.5712\n",
            "Epoch 8 Batch 50 Loss 2.0893 Accuracy 0.5858\n",
            "Epoch 8 Batch 100 Loss 2.0961 Accuracy 0.5860\n",
            "Epoch 8 Batch 150 Loss 2.0919 Accuracy 0.5868\n",
            "Epoch 8 Batch 200 Loss 2.1044 Accuracy 0.5860\n",
            "Epoch 8 Batch 250 Loss 2.1115 Accuracy 0.5853\n",
            "Epoch 8 Batch 300 Loss 2.1145 Accuracy 0.5852\n",
            "Epoch 8 Batch 350 Loss 2.1162 Accuracy 0.5853\n",
            "Epoch 8 Batch 400 Loss 2.1168 Accuracy 0.5851\n",
            "Epoch 8 Batch 450 Loss 2.1188 Accuracy 0.5855\n",
            "Epoch 8 Loss 2.1205 Accuracy 0.5855\n",
            "Time taken for 1 epoch: 29.47 secs\n",
            "\n",
            "Epoch 9 Batch 0 Loss 1.8778 Accuracy 0.6019\n",
            "Epoch 9 Batch 50 Loss 1.8691 Accuracy 0.6177\n",
            "Epoch 9 Batch 100 Loss 1.8566 Accuracy 0.6219\n",
            "Epoch 9 Batch 150 Loss 1.8658 Accuracy 0.6204\n",
            "Epoch 9 Batch 200 Loss 1.8818 Accuracy 0.6193\n",
            "Epoch 9 Batch 250 Loss 1.8822 Accuracy 0.6196\n",
            "Epoch 9 Batch 300 Loss 1.8882 Accuracy 0.6194\n",
            "Epoch 9 Batch 350 Loss 1.8977 Accuracy 0.6185\n",
            "Epoch 9 Batch 400 Loss 1.8984 Accuracy 0.6185\n",
            "Epoch 9 Batch 450 Loss 1.8994 Accuracy 0.6192\n",
            "Epoch 9 Loss 1.9012 Accuracy 0.6190\n",
            "Time taken for 1 epoch: 38.81 secs\n",
            "\n",
            "Epoch 10 Batch 0 Loss 1.6451 Accuracy 0.6687\n",
            "Epoch 10 Batch 50 Loss 1.6047 Accuracy 0.6618\n",
            "Epoch 10 Batch 100 Loss 1.6176 Accuracy 0.6594\n",
            "Epoch 10 Batch 150 Loss 1.6312 Accuracy 0.6579\n",
            "Epoch 10 Batch 200 Loss 1.6472 Accuracy 0.6556\n",
            "Epoch 10 Batch 250 Loss 1.6550 Accuracy 0.6548\n",
            "Epoch 10 Batch 300 Loss 1.6680 Accuracy 0.6539\n",
            "Epoch 10 Batch 350 Loss 1.6742 Accuracy 0.6535\n",
            "Epoch 10 Batch 400 Loss 1.6763 Accuracy 0.6537\n",
            "Epoch 10 Batch 450 Loss 1.6812 Accuracy 0.6536\n",
            "Saving checkpoint for epoch 10 at ./checkpoints/cn_en/train/ckpt-2\n",
            "Epoch 10 Loss 1.6824 Accuracy 0.6537\n",
            "Time taken for 1 epoch: 29.40 secs\n",
            "\n",
            "Epoch 11 Batch 0 Loss 1.2617 Accuracy 0.7246\n",
            "Epoch 11 Batch 50 Loss 1.4272 Accuracy 0.6892\n",
            "Epoch 11 Batch 100 Loss 1.4314 Accuracy 0.6867\n",
            "Epoch 11 Batch 150 Loss 1.4412 Accuracy 0.6866\n",
            "Epoch 11 Batch 200 Loss 1.4533 Accuracy 0.6847\n",
            "Epoch 11 Batch 250 Loss 1.4619 Accuracy 0.6840\n",
            "Epoch 11 Batch 300 Loss 1.4736 Accuracy 0.6842\n",
            "Epoch 11 Batch 350 Loss 1.4806 Accuracy 0.6838\n",
            "Epoch 11 Batch 400 Loss 1.4852 Accuracy 0.6836\n",
            "Epoch 11 Batch 450 Loss 1.4921 Accuracy 0.6832\n",
            "Epoch 11 Loss 1.4905 Accuracy 0.6834\n",
            "Time taken for 1 epoch: 31.97 secs\n",
            "\n",
            "Epoch 12 Batch 0 Loss 1.1801 Accuracy 0.7389\n",
            "Epoch 12 Batch 50 Loss 1.2444 Accuracy 0.7224\n",
            "Epoch 12 Batch 100 Loss 1.2621 Accuracy 0.7195\n",
            "Epoch 12 Batch 150 Loss 1.2727 Accuracy 0.7181\n",
            "Epoch 12 Batch 200 Loss 1.2863 Accuracy 0.7159\n",
            "Epoch 12 Batch 250 Loss 1.2941 Accuracy 0.7148\n",
            "Epoch 12 Batch 300 Loss 1.3038 Accuracy 0.7132\n",
            "Epoch 12 Batch 350 Loss 1.3168 Accuracy 0.7118\n",
            "Epoch 12 Batch 400 Loss 1.3260 Accuracy 0.7110\n",
            "Epoch 12 Batch 450 Loss 1.3382 Accuracy 0.7094\n",
            "Epoch 12 Loss 1.3395 Accuracy 0.7094\n",
            "Time taken for 1 epoch: 28.74 secs\n",
            "\n",
            "Epoch 13 Batch 0 Loss 1.1416 Accuracy 0.7571\n",
            "Epoch 13 Batch 50 Loss 1.1109 Accuracy 0.7436\n",
            "Epoch 13 Batch 100 Loss 1.1297 Accuracy 0.7414\n",
            "Epoch 13 Batch 150 Loss 1.1486 Accuracy 0.7380\n",
            "Epoch 13 Batch 200 Loss 1.1603 Accuracy 0.7365\n",
            "Epoch 13 Batch 250 Loss 1.1686 Accuracy 0.7351\n",
            "Epoch 13 Batch 300 Loss 1.1800 Accuracy 0.7339\n",
            "Epoch 13 Batch 350 Loss 1.1907 Accuracy 0.7329\n",
            "Epoch 13 Batch 400 Loss 1.2041 Accuracy 0.7314\n",
            "Epoch 13 Batch 450 Loss 1.2119 Accuracy 0.7309\n",
            "Epoch 13 Loss 1.2135 Accuracy 0.7309\n",
            "Time taken for 1 epoch: 29.94 secs\n",
            "\n",
            "Epoch 14 Batch 0 Loss 0.9877 Accuracy 0.7832\n",
            "Epoch 14 Batch 50 Loss 1.0084 Accuracy 0.7650\n",
            "Epoch 14 Batch 100 Loss 1.0307 Accuracy 0.7605\n",
            "Epoch 14 Batch 150 Loss 1.0374 Accuracy 0.7586\n",
            "Epoch 14 Batch 200 Loss 1.0464 Accuracy 0.7572\n",
            "Epoch 14 Batch 250 Loss 1.0601 Accuracy 0.7553\n",
            "Epoch 14 Batch 300 Loss 1.0692 Accuracy 0.7541\n",
            "Epoch 14 Batch 350 Loss 1.0818 Accuracy 0.7520\n",
            "Epoch 14 Batch 400 Loss 1.0925 Accuracy 0.7506\n",
            "Epoch 14 Batch 450 Loss 1.1014 Accuracy 0.7497\n",
            "Epoch 14 Loss 1.1041 Accuracy 0.7494\n",
            "Time taken for 1 epoch: 28.93 secs\n",
            "\n",
            "Epoch 15 Batch 0 Loss 0.8413 Accuracy 0.7831\n",
            "Epoch 15 Batch 50 Loss 0.9036 Accuracy 0.7827\n",
            "Epoch 15 Batch 100 Loss 0.9254 Accuracy 0.7794\n",
            "Epoch 15 Batch 150 Loss 0.9405 Accuracy 0.7762\n",
            "Epoch 15 Batch 200 Loss 0.9533 Accuracy 0.7739\n",
            "Epoch 15 Batch 250 Loss 0.9630 Accuracy 0.7723\n",
            "Epoch 15 Batch 300 Loss 0.9722 Accuracy 0.7712\n",
            "Epoch 15 Batch 350 Loss 0.9836 Accuracy 0.7694\n",
            "Epoch 15 Batch 400 Loss 0.9932 Accuracy 0.7683\n",
            "Epoch 15 Batch 450 Loss 1.0035 Accuracy 0.7669\n",
            "Saving checkpoint for epoch 15 at ./checkpoints/cn_en/train/ckpt-3\n",
            "Epoch 15 Loss 1.0073 Accuracy 0.7663\n",
            "Time taken for 1 epoch: 29.38 secs\n",
            "\n",
            "Epoch 16 Batch 0 Loss 0.7700 Accuracy 0.7893\n",
            "Epoch 16 Batch 50 Loss 0.8112 Accuracy 0.8036\n",
            "Epoch 16 Batch 100 Loss 0.8386 Accuracy 0.7969\n",
            "Epoch 16 Batch 150 Loss 0.8431 Accuracy 0.7959\n",
            "Epoch 16 Batch 200 Loss 0.8576 Accuracy 0.7931\n",
            "Epoch 16 Batch 250 Loss 0.8747 Accuracy 0.7897\n",
            "Epoch 16 Batch 300 Loss 0.8884 Accuracy 0.7874\n",
            "Epoch 16 Batch 350 Loss 0.9008 Accuracy 0.7853\n",
            "Epoch 16 Batch 400 Loss 0.9103 Accuracy 0.7839\n",
            "Epoch 16 Batch 450 Loss 0.9191 Accuracy 0.7829\n",
            "Epoch 16 Loss 0.9229 Accuracy 0.7822\n",
            "Time taken for 1 epoch: 28.74 secs\n",
            "\n",
            "Epoch 17 Batch 0 Loss 0.8532 Accuracy 0.8105\n",
            "Epoch 17 Batch 50 Loss 0.7598 Accuracy 0.8126\n",
            "Epoch 17 Batch 100 Loss 0.7651 Accuracy 0.8125\n",
            "Epoch 17 Batch 150 Loss 0.7738 Accuracy 0.8105\n",
            "Epoch 17 Batch 200 Loss 0.7876 Accuracy 0.8071\n",
            "Epoch 17 Batch 250 Loss 0.8047 Accuracy 0.8032\n",
            "Epoch 17 Batch 300 Loss 0.8166 Accuracy 0.8008\n",
            "Epoch 17 Batch 350 Loss 0.8242 Accuracy 0.8002\n",
            "Epoch 17 Batch 400 Loss 0.8362 Accuracy 0.7983\n",
            "Epoch 17 Batch 450 Loss 0.8470 Accuracy 0.7967\n",
            "Epoch 17 Loss 0.8510 Accuracy 0.7961\n",
            "Time taken for 1 epoch: 28.99 secs\n",
            "\n",
            "Epoch 18 Batch 0 Loss 0.6700 Accuracy 0.8228\n",
            "Epoch 18 Batch 50 Loss 0.7030 Accuracy 0.8201\n",
            "Epoch 18 Batch 100 Loss 0.7125 Accuracy 0.8198\n",
            "Epoch 18 Batch 150 Loss 0.7260 Accuracy 0.8175\n",
            "Epoch 18 Batch 200 Loss 0.7332 Accuracy 0.8160\n",
            "Epoch 18 Batch 250 Loss 0.7442 Accuracy 0.8141\n",
            "Epoch 18 Batch 300 Loss 0.7524 Accuracy 0.8128\n",
            "Epoch 18 Batch 350 Loss 0.7629 Accuracy 0.8112\n",
            "Epoch 18 Batch 400 Loss 0.7739 Accuracy 0.8093\n",
            "Epoch 18 Batch 450 Loss 0.7840 Accuracy 0.8078\n",
            "Epoch 18 Loss 0.7878 Accuracy 0.8073\n",
            "Time taken for 1 epoch: 29.08 secs\n",
            "\n",
            "Epoch 19 Batch 0 Loss 0.6791 Accuracy 0.8298\n",
            "Epoch 19 Batch 50 Loss 0.6439 Accuracy 0.8342\n",
            "Epoch 19 Batch 100 Loss 0.6549 Accuracy 0.8323\n",
            "Epoch 19 Batch 150 Loss 0.6645 Accuracy 0.8298\n",
            "Epoch 19 Batch 200 Loss 0.6689 Accuracy 0.8290\n",
            "Epoch 19 Batch 250 Loss 0.6778 Accuracy 0.8273\n",
            "Epoch 19 Batch 300 Loss 0.6915 Accuracy 0.8247\n",
            "Epoch 19 Batch 350 Loss 0.7072 Accuracy 0.8220\n",
            "Epoch 19 Batch 400 Loss 0.7179 Accuracy 0.8202\n",
            "Epoch 19 Batch 450 Loss 0.7327 Accuracy 0.8179\n",
            "Epoch 19 Loss 0.7355 Accuracy 0.8176\n",
            "Time taken for 1 epoch: 31.89 secs\n",
            "\n",
            "Epoch 20 Batch 0 Loss 0.5608 Accuracy 0.8424\n",
            "Epoch 20 Batch 50 Loss 0.5804 Accuracy 0.8496\n",
            "Epoch 20 Batch 100 Loss 0.5916 Accuracy 0.8462\n",
            "Epoch 20 Batch 150 Loss 0.6101 Accuracy 0.8420\n",
            "Epoch 20 Batch 200 Loss 0.6238 Accuracy 0.8388\n",
            "Epoch 20 Batch 250 Loss 0.6378 Accuracy 0.8355\n",
            "Epoch 20 Batch 300 Loss 0.6439 Accuracy 0.8344\n",
            "Epoch 20 Batch 350 Loss 0.6565 Accuracy 0.8325\n",
            "Epoch 20 Batch 400 Loss 0.6689 Accuracy 0.8300\n",
            "Epoch 20 Batch 450 Loss 0.6798 Accuracy 0.8282\n",
            "Saving checkpoint for epoch 20 at ./checkpoints/cn_en/train/ckpt-4\n",
            "Epoch 20 Loss 0.6845 Accuracy 0.8275\n",
            "Time taken for 1 epoch: 29.69 secs\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t9tVAR9hKHDs",
        "outputId": "5c6baa40-3cff-4e59-cc5c-f0c912ff9365"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class Translator(tf.Module):\n",
        "    def __init__(self, input_text_processor, output_text_processor, transformer):\n",
        "        self.tokenizers_pt = input_text_processor\n",
        "        self.tokenizers_en = output_text_processor\n",
        "        #这里遇到一个问题\n",
        "        #后面我们要保存模型\n",
        "        #我们定义一个类并把Translator它包装在另一个tf.Module子类中，这次使用tf.function方法__call__：\n",
        "        #这时会报一个错误\n",
        "        #OperatorNotAllowedInGraphError: using a tf.Tensor as a Python bool is not allowed:\n",
        "        #AutoGraph is disabled in this function. Try decorating it directly with @tf.function.\n",
        "        #这是因为我把tf.keras.layers.StringLookup放到了__call__方法里\n",
        "        #把这个方法拿出来，放到初始化里就可以了\n",
        "        self.output_token_string_from_index = (\n",
        "        tf.keras.layers.StringLookup(\n",
        "            vocabulary=output_text_processor.get_vocabulary(),\n",
        "            mask_token='',\n",
        "            invert=True))\n",
        "        self.transformer = transformer\n",
        "\n",
        "    def __call__(self, sentence, max_length=20):\n",
        "        #输入中文句子，并添加了开始和结束标记\n",
        "        #assert判读输入的句子是不是tf.Tensor张量类型\n",
        "        assert isinstance(sentence, tf.Tensor)\n",
        "\n",
        "        #如果句子的形状是0，我们给句子加入一个维度\n",
        "        if len(sentence.shape) == 0:\n",
        "            sentence = sentence[tf.newaxis]\n",
        "\n",
        "        #把句子变成相应的数字\n",
        "        sentence = self.tokenizers_pt(sentence)\n",
        "\n",
        "        encoder_input = sentence\n",
        "\n",
        "        #因为目标是英语，所以transformer的第一个标记应该是英语起始标记。\n",
        "        #这里我们输入一个空句子，产生一个start 和 end 的 token 是[2, 3]\n",
        "        start_and_end = self.tokenizers_en([''])[0]\n",
        "        #取出 start的 token 并加入一个维度\n",
        "        start = start_and_end[0][tf.newaxis]\n",
        "        #取出 end的 token 并加入一个维度\n",
        "        end = start_and_end[1][tf.newaxis]\n",
        "\n",
        "\n",
        "        #在部分网络结构，尤其是涉及到时间序列的结构中，\n",
        "        #我们可能需要将一系列张量以数组的方式依次存放起来，以供进一步处理。\n",
        "        #当然，在即时执行模式下，你可以直接使用一个 Python 列表(List)存放数组。\n",
        "        #不过，如果你需要基于计算图的特性(例如使用 @tf.function 加速模型运行\n",
        "        #或者使用 SavedModel 导出模型)，就无法使用这种方式了。\n",
        "        #因此，TensorFlow 提供了 tf.TensorArray ，\n",
        "        #一种支持计算图特性的 TensorFlow 动态数组。\n",
        "\n",
        "        #dynamic_size 参数设置为 True ，则该数组会自动增长空间。\n",
        "        output_array = tf.TensorArray(dtype=tf.int64, size=0, dynamic_size=True)\n",
        "        #write(index, value) ：将 value 写入数组的第 index 个位置;\n",
        "        output_array = output_array.write(0, start)\n",
        "\n",
        "\n",
        "        for i in tf.range(max_length):\n",
        "            #output_array.stack()返回output_array里所有值\n",
        "            #tf.transpose是转制tensor形状，例如output_array插入2个值后\n",
        "            #shape是（2，1）tf.transpose变成（1，2）\n",
        "            output = tf.transpose(output_array.stack())\n",
        "\n",
        "            #输入句子和output的值产生一个预测值 (batch_size, tar_seq_len, target_vocab_size)\n",
        "            #这里我们输入的是1个句子，batch_size = 1\n",
        "            #tar_seq_len 大小是随着output的第二个维度变化的，1，2，3，\n",
        "            #target_vocab_size 大小是不变的，一直是固定值\n",
        "            #（1, 1, 8000), (1, 2, 8000), (1, 3, 8000)\n",
        "            predictions, _ = self.transformer([encoder_input, output], training=False)\n",
        "\n",
        "            #从seq_len维度中选择最后一个token\n",
        "            #这样我们每次循环取的就是最后一个单词预测的值\n",
        "            predictions = predictions[:, -1:, :]\n",
        "\n",
        "            #取最后一个维度也就是target_vocab_size里的最大值\n",
        "            predicted_id = tf.argmax(predictions, axis=-1)\n",
        "\n",
        "            #把预测值添加到output_array\n",
        "            output_array = output_array.write(i+1, predicted_id[0])\n",
        "\n",
        "            #如果预测的id值等于end值，说明预测结束，跳出循环\n",
        "            #如果没有出现end值，那就直到循环结束\n",
        "            if predicted_id == end:\n",
        "                break\n",
        "\n",
        "        #output_array.stack()取出output_array里所有的值\n",
        "        #也就是我们预测的整个句子，shape是（tokens, 1)\n",
        "        #tokens 大小就是句子的长度\n",
        "        #tf.transpose 把output_array变成 （1，tokens）\n",
        "        output = tf.transpose(output_array.stack())\n",
        "\n",
        "        #获得所有en_vocab的值\n",
        "        #output_vocab = np.array(self.tokenizers_en.get_vocabulary())\n",
        "        # output_vocab = tf.keras.layers.StringLookup(\n",
        "        #     vocabulary=self.tokenizers_en.get_vocabulary(),\n",
        "        #     mask_token='', #表示屏蔽输入的标记。就是空值不输入。\n",
        "        #     invert=True)\n",
        "\n",
        "        #取出所有预测的单词\n",
        "        #result_text_tokens = output_vocab[output[0].numpy()]\n",
        "        result_text_tokens = self.output_token_string_from_index(output)\n",
        "\n",
        "        #去掉start 和 end\n",
        "        #text_tokens = result_text_tokens[1:-1]\n",
        "        text_tokens = result_text_tokens[:, 1:-1]\n",
        "\n",
        "        #把所有的单词链接成句子\n",
        "        #text = ' '.join(text_tokens)\n",
        "        text = tf.strings.reduce_join(text_tokens, axis=1, separator=' ')\n",
        "\n",
        "\n",
        "        _, attention_weights = self.transformer([encoder_input, output[:,:-1]], training=False)\n",
        "\n",
        "        return text[0], result_text_tokens, attention_weights"
      ],
      "metadata": {
        "id": "OFR-IL0BDICK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#打印结果\n",
        "def print_translation(sentence, tokens, ground_truth):\n",
        "    print(f'{\"Input:\":15s}: {sentence}') #输入的句子\n",
        "    print(f'{\"Prediction\":15s}: {tokens.numpy().decode(\"utf-8\")}') #预测值\n",
        "    print(f'{\"Ground truth\":15s}: {ground_truth}') #网易有道翻译结果"
      ],
      "metadata": {
        "id": "8eF-nYXUDLmZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translator = Translator(input_text_processor, output_text_processor, transformer)\n"
      ],
      "metadata": {
        "id": "DLZG_JPeDPBm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sentence = \"今天天气很好。\"\n",
        "ground_truth = \"The weather is fine today.\""
      ],
      "metadata": {
        "id": "DiDeS71DDQoS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "translated_text, translated_tokens, attention_weights = translator(\n",
        "    tf.constant(proce_cn_sentence(sentence)))\n",
        "print_translation(sentence, translated_text, ground_truth)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nUgu_HUEDSKZ",
        "outputId": "8e7341f3-7028-4f56-cbbd-b9ad1b0e7544"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:         : 今天天气很好。\n",
            "Prediction     : the weather is very good today .\n",
            "Ground truth   : The weather is fine today.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "jVti-8ORNoVt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}